{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import scipy \n",
    "import tensorflow as tf\n",
    "\n",
    "import imageio\n",
    "import gzip\n",
    "from PIL import Image\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.pyplot as plt\n",
    "#from tqdm import trange, tqdm\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop, Optimizer\n",
    "from keras.callbacks import Callback\n",
    "from collections import OrderedDict\n",
    "\n",
    "from helpers import utils\n",
    "# from helpers import protocols\n",
    "# from helpers.keras_utils import LossHistory\n",
    "# from helpers.optimizers import KOOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTRACT LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# Extract labels from MNIST labels into vector\n",
    "def extract_labels(filename, num_images):\n",
    "  with gzip.open(filename) as bytestream:\n",
    "    bytestream.read(8)\n",
    "    buf = bytestream.read(1 * num_images)\n",
    "    labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "  return labels\n",
    "\n",
    "train_labels = extract_labels(\"MNIST-data/train-labels-idx1-ubyte.gz\", 60000)\n",
    "eval_labels = extract_labels(\"MNIST-data/t10k-labels-idx1-ubyte.gz\", 10000)\n",
    "print(np.shape(train_labels))\n",
    "print(np.shape(eval_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONSTRUCT DATASETS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# original train\n",
    "train_original = np.zeros((60000,28,28), dtype=np.float32)\n",
    "images_original = [\"MNIST-processed-training/original/original{0}.png\".format(k) for k in range(1,60000)]\n",
    "\n",
    "for i in range(len(images_original)):\n",
    "    img = np.array(Image.open(images_original[i]))\n",
    "    train_original[i, :, :] = img\n",
    " \n",
    "print(np.shape(train_original))\n",
    "\n",
    "# original test\n",
    "eval_original = np.zeros((10000,28,28), dtype=np.float32)\n",
    "images2_original = [\"MNIST-processed-test/original/test-original{0}.png\".format(k) for k in range(1,10001)]\n",
    "\n",
    "for i in range(len(images2_original)):\n",
    "    img = np.array(Image.open(images2_original[i]))\n",
    "    eval_original[i, :, :] = img\n",
    " \n",
    "print(np.shape(eval_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# ROTATE 90 train\n",
    "train_rot90 = np.zeros((60000,28,28), dtype=np.float32)\n",
    "images_rot90 = [\"MNIST-processed-training/rot90/rot90{0}.png\".format(k) for k in range(1,60000)]\n",
    "\n",
    "for i in range(len(images_rot90)):\n",
    "    img = np.array(Image.open(images_rot90[i]))\n",
    "    train_rot90[i, :, :] = img\n",
    " \n",
    "print(np.shape(train_rot90))\n",
    "\n",
    "# ROTATE 90 test\n",
    "eval_rot90 = np.zeros((10000,28,28), dtype=np.float32)\n",
    "images2_rot90 = [\"MNIST-processed-test/rot90/test-rot90{0}.png\".format(k) for k in range(1,10001)]\n",
    "\n",
    "for i in range(len(images2_rot90)):\n",
    "    img = np.array(Image.open(images2_rot90[i]))\n",
    "    eval_rot90[i, :, :] = img\n",
    " \n",
    "print(np.shape(eval_rot90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkerboard train\n",
    "train_checkerboard = np.zeros((60000,28,28), dtype=np.float32)\n",
    "images_checkerboard = [\"MNIST-processed-training/checkerboard/fullcheck{0}.png\".format(k) for k in range(1,60000)]\n",
    "\n",
    "for i in range(len(images_checkerboard)):\n",
    "    img = np.array(Image.open(images_checkerboard[i]))\n",
    "    train_checkerboard[i, :, :] = img\n",
    " \n",
    "print(np.shape(train_checkerboard))\n",
    "\n",
    "# checkerboard test\n",
    "eval_checkerboard = np.zeros((10000,28,28), dtype=np.float32)\n",
    "images2_checkerboard = [\"MNIST-processed-test/checkerboard/test-checkerboard{0}.png\".format(k) for k in range(1,10001)]\n",
    "\n",
    "for i in range(len(images2_checkerboard)):\n",
    "    img = np.array(Image.open(images2_checkerboard[i]))\n",
    "    eval_checkerboard[i, :, :] = img\n",
    " \n",
    "print(np.shape(eval_checkerboard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INV train\n",
    "train_inv = np.zeros((60000,28,28), dtype=np.float32)\n",
    "images_inv = [\"MNIST-processed-training/Inv/inv{0}.png\".format(k) for k in range(1,60000)]\n",
    "\n",
    "for i in range(len(images_inv)):\n",
    "    img = np.array(Image.open(images_inv[i]))\n",
    "    train_inv[i, :, :] = img\n",
    " \n",
    "print(np.shape(train_inv))\n",
    "\n",
    "# INV test\n",
    "eval_inv = np.zeros((10000,28,28), dtype=np.float32)\n",
    "images2_inv = [\"MNIST-processed-test/inv/test-inv{0}.png\".format(k) for k in range(1,10001)]\n",
    "\n",
    "for i in range(len(images2_inv)):\n",
    "    img = np.array(Image.open(images2_inv[i]))\n",
    "    eval_inv[i, :, :] = img\n",
    " \n",
    "print(np.shape(eval_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invbot train\n",
    "train_invbot = np.zeros((60000,28,28), dtype=np.float32)\n",
    "images_invbot = [\"MNIST-processed-training/invbot/invbot{0}.png\".format(k) for k in range(1,60000)]\n",
    "\n",
    "for i in range(len(images_invbot)):\n",
    "    img = np.array(Image.open(images_invbot[i]))\n",
    "    train_invbot[i, :, :] = img\n",
    " \n",
    "print(np.shape(train_invbot))\n",
    "\n",
    "# invbot test\n",
    "eval_invbot = np.zeros((10000,28,28), dtype=np.float32)\n",
    "images2_invbot = [\"MNIST-processed-test/invbot/test-invbot{0}.png\".format(k) for k in range(1,10001)]\n",
    "\n",
    "for i in range(len(images2_invbot)):\n",
    "    img = np.array(Image.open(images2_invbot[i]))\n",
    "    eval_invbot[i, :, :] = img\n",
    " \n",
    "print(np.shape(eval_invbot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fliplr train\n",
    "train_fliplr = np.zeros((60000,28,28), dtype=np.float32)\n",
    "images_fliplr = [\"MNIST-processed-training/fliplr/fliplr{0}.png\".format(k) for k in range(1,60000)]\n",
    "\n",
    "for i in range(len(images_fliplr)):\n",
    "    img = np.array(Image.open(images_fliplr[i]))\n",
    "    train_fliplr[i, :, :] = img\n",
    " \n",
    "print(np.shape(train_fliplr))\n",
    "\n",
    "# fliplr test\n",
    "eval_fliplr = np.zeros((10000,28,28), dtype=np.float32)\n",
    "images2_fliplr = [\"MNIST-processed-test/fliplr/test-fliplr{0}.png\".format(k) for k in range(1,10001)]\n",
    "\n",
    "for i in range(len(images2_fliplr)):\n",
    "    img = np.array(Image.open(images2_fliplr[i]))\n",
    "    eval_fliplr[i, :, :] = img\n",
    " \n",
    "print(np.shape(eval_fliplr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutud train\n",
    "train_cutud = np.zeros((60000,28,28), dtype=np.float32)\n",
    "images_cutud = [\"MNIST-processed-training/cutud/cutUD{0}.png\".format(k) for k in range(1,60000)]\n",
    "\n",
    "for i in range(len(images_cutud)):\n",
    "    img = np.array(Image.open(images_cutud[i]))\n",
    "    train_cutud[i, :, :] = img\n",
    " \n",
    "print(np.shape(train_cutud))\n",
    "\n",
    "# cutud test\n",
    "eval_cutud = np.zeros((10000,28,28), dtype=np.float32)\n",
    "images2_cutud = [\"MNIST-processed-test/cutud/test-cutud{0}.png\".format(k) for k in range(1,10001)]\n",
    "\n",
    "for i in range(len(images2_cutud)):\n",
    "    img = np.array(Image.open(images2_cutud[i]))\n",
    "    eval_cutud[i, :, :] = img\n",
    " \n",
    "print(np.shape(eval_cutud))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flipud train\n",
    "train_flipud = np.zeros((60000,28,28), dtype=np.float32)\n",
    "images_flipud = [\"MNIST-processed-training/flipud/flipud{0}.png\".format(k) for k in range(1,60000)]\n",
    "\n",
    "for i in range(len(images_flipud)):\n",
    "    img = np.array(Image.open(images_flipud[i]))\n",
    "    train_flipud[i, :, :] = img\n",
    " \n",
    "print(np.shape(train_data))\n",
    "\n",
    "# flipud test\n",
    "eval_flipud = np.zeros((10000,28,28), dtype=np.float32)\n",
    "images2_flipud = [\"MNIST-processed-test/flipud/test-flipud{0}.png\".format(k) for k in range(1,10001)]\n",
    "\n",
    "for i in range(len(images2_flipud)):\n",
    "    img = np.array(Image.open(images2_flipud[i]))\n",
    "    eval_flipud[i, :, :] = img\n",
    " \n",
    "print(np.shape(eval_flipud))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data params\n",
    "# input_dim = 784\n",
    "# output_dim = 10\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# # Network params\n",
    "# n_hidden_units = 2000\n",
    "# activation_fn = tf.nn.relu\n",
    "\n",
    "# Optimization params\n",
    "batch_size = 256\n",
    "num_classes = 10\n",
    "epochs = 5 # epochs per task\n",
    "# learning_rate=1e-3\n",
    "# xi = 0.1\n",
    "\n",
    "# Reset optimizer after each age\n",
    "# reset_optimizer = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train labels shape: (60000,)\n",
      "test labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# the data, train and test sets\n",
    "x_train = train_original\n",
    "x_test = eval_original\n",
    "y_train = train_labels\n",
    "y_test = eval_labels\n",
    "\n",
    "print('train labels shape:', y_train.shape)\n",
    "print('test labels shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "train labels shape: (60000, 10)\n",
      "test labels shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# ?\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "# ?\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('train labels shape:', y_train.shape)\n",
    "print('test labels shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONSTRUCT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 175s 3ms/step - loss: 0.0979 - acc: 0.9704 - val_loss: 0.0516 - val_acc: 0.9826\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 175s 3ms/step - loss: 0.0740 - acc: 0.9778 - val_loss: 0.0644 - val_acc: 0.9781\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 169s 3ms/step - loss: 0.0621 - acc: 0.9816 - val_loss: 0.0353 - val_acc: 0.9886\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 166s 3ms/step - loss: 0.0558 - acc: 0.9834 - val_loss: 0.0320 - val_acc: 0.9888\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 174s 3ms/step - loss: 0.0475 - acc: 0.9854 - val_loss: 0.0301 - val_acc: 0.9898\n",
      "Test loss: 0.03006382731956255\n",
      "Test accuracy: 0.9898\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "# Convolutional layer 1 and input layer\n",
    "model2.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "\n",
    "# Convolutional layer 2\n",
    "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Pooling layer 1\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Dropout layer with flattening\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(Flatten())\n",
    "\n",
    "# Dense layer 1 with dropout \n",
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "\n",
    "# Dense layer 2\n",
    "model2.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model2.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "model.save('trained_model.h5')\n",
    "# del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload model\n",
    "model2 = load_model('trained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# the second data set\n",
    "x_train2 = train_rot90\n",
    "x_test2 = eval_rot90\n",
    "print(x_train2.shape)\n",
    "print(x_test2.shape)\n",
    "\n",
    "y_train = train_labels\n",
    "y_test = eval_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train2 shape: (60000, 28, 28, 1)\n",
      "x_test2 shape: (10000, 28, 28, 1)\n",
      "60000 train2 samples\n",
      "10000 test2 samples\n",
      "train labels shape: (60000, 10)\n",
      "test labels shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# ?\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train2 = x_train2.reshape(x_train2.shape[0], 1, img_rows, img_cols)\n",
    "    x_test2 = x_test2.reshape(x_test2.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train2 = x_train2.reshape(x_train2.shape[0], img_rows, img_cols, 1)\n",
    "    x_test2 = x_test2.reshape(x_test2.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "# ?\n",
    "x_train2 = x_train2.astype('float32')\n",
    "x_test2 = x_test2.astype('float32')\n",
    "x_train2 /= 255\n",
    "x_test2 /= 255\n",
    "print('x_train2 shape:', x_train2.shape)\n",
    "print('x_test2 shape:', x_test2.shape)\n",
    "print(x_train2.shape[0], 'train2 samples')\n",
    "print(x_test2.shape[0], 'test2 samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('train labels shape:', y_train.shape)\n",
    "print('test labels shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.3183 - acc: 0.9066 - val_loss: 0.9160 - val_acc: 0.7349\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 195s 3ms/step - loss: 0.1104 - acc: 0.9673 - val_loss: 1.8853 - val_acc: 0.5208\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 177s 3ms/step - loss: 0.0844 - acc: 0.9749 - val_loss: 1.8937 - val_acc: 0.5220\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 175s 3ms/step - loss: 0.0693 - acc: 0.9792 - val_loss: 2.0058 - val_acc: 0.5056\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0609 - acc: 0.9819 - val_loss: 2.8436 - val_acc: 0.4279\n",
      "Original data set\n",
      "Test loss: 2.843556359291077\n",
      "Test accuracy: 0.4279\n",
      "Second data set\n",
      "Test loss: 0.03505487792348286\n",
      "Test accuracy: 0.9889\n"
     ]
    }
   ],
   "source": [
    "# Continue training\n",
    "model2.fit(x_train2, y_train, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score1 = model2.evaluate(x_test, y_test, verbose=0)\n",
    "score2 = model2.evaluate(x_test2, y_test, verbose=0)\n",
    "\n",
    "print('Original data set')\n",
    "print('Test loss:', score1[0])\n",
    "print('Test accuracy:', score1[1])\n",
    "\n",
    "print('Second data set')\n",
    "print('Test loss:', score2[0])\n",
    "print('Test accuracy:', score2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "\n",
    "    # Input Layer\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "    # Convolutional layer 1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs = input_layer,\n",
    "        filters = 32,\n",
    "        kernel_size=[5,5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu\n",
    "    )\n",
    "\n",
    "    # Pooling 1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Convolutional layer 2 and pooling layer\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[5,5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu\n",
    "    )\n",
    "\n",
    "    # Pooling 2 with flattening\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2,2], strides=2)\n",
    "    pool2_flat=tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "    # Dense layer with dropout \n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "    dropout=tf.layers.dropout(inputs=dense, rate=0.4, training=mode==tf.estimator.ModeKeys.TRAIN)\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "    # Generate predictions\n",
    "    predictions = {\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Caluclate loss\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    # Configure training op\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])}\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")\n",
    "\n",
    "# Logging predictions\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, \n",
    "    every_n_iter=50)\n",
    "\n",
    "# Our application logic will be added here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(unused_argv):\n",
    "    # Training on original\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\":train_original},\n",
    "        y=train_labels,\n",
    "        batch_size=1000,\n",
    "        num_epochs=None,\n",
    "        shuffle=True)\n",
    "    \n",
    "    mnist_classifier.train(\n",
    "        input_fn=train_input_fn,\n",
    "        steps=200,\n",
    "        hooks=[logging_hook])\n",
    "\n",
    "    # Evaluation on original\n",
    "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": eval_original},\n",
    "        y=eval_labels,\n",
    "        num_epochs=1,\n",
    "        shuffle=False)\n",
    "    \n",
    "    eval_results=mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "    print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  tf.app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
